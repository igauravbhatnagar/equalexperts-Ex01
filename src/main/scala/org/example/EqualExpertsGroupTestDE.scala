package org.example

import com.databricks.spark.xml._
import com.typesafe.config.{Config, ConfigFactory}
import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.SparkSession

import java.time.format.DateTimeFormatter
import java.time.{LocalDate, LocalDateTime} // Add the DataFrame.read.xml() method

object EqualExpertsGroupTestDE extends App {
  // /////////////////////////////////////////////
  // Spark Session
  ///////////////////////////////////////////////
  val spark = SparkSession.builder
    .appName("Equalexperts_sc01") // optional and will be autogenerated if not specified
    .master("local[*]") // only for demo and testing purposes, use spark-submit instead
    .getOrCreate

  ///////////////////////////////////////////////
  // Spark configs and initial variables
  ///////////////////////////////////////////////
  val configs: Config = ConfigFactory.load("properties.conf")
  val deltaflag = configs.getString("internal_configs.deltaFlag")

  // Set Input Locations
  val inpDataPosts = configs.getString("paths.postsInputDir")
  val inpDataUsers = configs.getString("paths.usersInputDir")

  // Set Output Locations
  val outputLocPosts = configs.getString("paths.postsOutlocation")
  val outputLocUsers = configs.getString("paths.usersOutlocation")

  // Read Input Data - Input schema inferred automatically
  val inpPostsDF = spark.read
  .option("rootTag", "posts")
  .option("rowTag", "row")
  .xml(s"$inpDataPosts")

  val inpUsersDF = spark.read
  .option("rootTag", "users")
  .option("rowTag", "row")
  .xml(s"$inpDataUsers")

  //Register Temp views
  inpPostsDF.createOrReplaceTempView("posts")
  inpUsersDF.createOrReplaceTempView("users")

  // Logger
  val rootLogger = Logger.getRootLogger
  rootLogger.setLevel(Level.ERROR)

  // Date and Time Variables
  val dateToday = LocalDate.now()
  val TimeToday = LocalDateTime.now()
  val dateFormat = "ddMMYYYY"
  val fmtYear = "YYYY"
  val fmtMonth = "MM"
  val fmtDay = "dd"
  val TimeStampFormat = "ddMMYYYY"

  val formattedDate = dateToday.format(DateTimeFormatter.ofPattern("ddMMYYYY"))
  val formattedTime=  TimeToday.format(DateTimeFormatter.ofPattern("YYYY-MM-dd HH:mm:ss"))
  val tsFormat: String = "2018-01-01T12:15:00Z"

  ////////////////////////////////////
  // Use Sql in code to join two tables
  ////////////////////////////////////
// Most active users in 2020 as per Posts Created

  val usersActiveIn2020 = spark.sql("Select u._AccountId,u._DisplayName,u._Location,u._Reputation, count(*) as total_posts_2020 from users u join posts p on u._AccountId == p._OwnerUserId and substr(p._CreationDate,0,4) = '2020' GROUP BY u._AccountId,u._DisplayName,u._Location,u._Reputation ORDER BY total_posts_2020 Desc ")

  usersActiveIn2020.show()

  ////////////////////////////////////////////////////////////////////////////////////////////////////
  // WRITE tables to Hive external location Parquet ( use deltaFlag to check if Delta or history Load)
  ////////////////////////////////////////////////////////////////////////////////////////////////////

  inpPostsDF.write.mode("overwrite").parquet(outputLocPosts)
  inpUsersDF.write.mode("overwrite").parquet(outputLocUsers)

  //Uncomment to see Meta and Debug Info
  //  inpPostsDF.show()
  //  inpUsersDF.show()
  //  inpPostsDF.printSchema()
  //  inpUsersDF.printSchema()

}
